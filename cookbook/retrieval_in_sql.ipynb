{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incoporating semantic similarity in tabular databases\n",
    "\n",
    "In this notebook we will cover how to run semantic search over a specific table column within a single SQL query, combining tabular query with RAG.\n",
    "\n",
    "\n",
    "### Overall workflow\n",
    "\n",
    "1. Generating embeddings for a specific column\n",
    "2. Storing the embeddings in a new column (if column has low cardinality, it's better to use another table containing unique values and their embeddings)\n",
    "3. Querying using standard SQL queries with [PGVector](https://github.com/pgvector/pgvector) extension which allows using L2 distance (`<->`), Cosine distance (`<=>` or cosine similarity using `1 - <=>`) and Inner product (`<#>`)\n",
    "4. Running standard SQL query\n",
    "\n",
    "### Requirements\n",
    "\n",
    "We will need a PostgreSQL database with [pgvector](https://github.com/pgvector/pgvector) extension enabled. For this example, we will use a `Chinook` database using a local PostgreSQL server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get('OPENAI_API_KEY') or getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "CONNECTION_STRING = \"postgresql+psycopg2://postgres:test@localhost:5432/vectordb\" # Replace with your own\n",
    "db = SQLDatabase.from_uri(CONNECTION_STRING)\n",
    "llm = ChatOpenAI(model_name='gpt-4', temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding the song titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will run queries based on semantic meaning of song titles. In order to do this, let's start by adding a new column in the table for storing the embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.run('ALTER TABLE \"Track\" ADD COLUMN \"embeddings\" vector;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate the embedding for each *track title* and store it as a new column in our \"Track\" table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = db.run('SELECT \"Name\" FROM \"Track\"')\n",
    "song_titles = [s[0] for s in eval(tracks)]\n",
    "# song_titles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3503"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_embeddings = embeddings_model.embed_documents(song_titles)\n",
    "len(title_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's insert the embeddings in the into the new column from our table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3503/3503 [00:27<00:00, 128.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(title_embeddings))):\n",
    "    title = titles[i].replace(\"'\",\"''\")\n",
    "    embedding = title_embeddings[i]\n",
    "    sql_command = f'UPDATE \"Track\" SET \"embeddings\" = ARRAY{embedding} WHERE \"Name\" =' +  f\"'{title}'\"\n",
    "    db.run(sql_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the semantic search running the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(\"Tomorrow\\'s Dream\",), (\\'Remember Tomorrow\\',), (\\'Remember Tomorrow\\',), (\\'The Best Is Yet To Come\\',), (\"Thinking \\'Bout Tomorrow\",)]'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_title = embeddings_model.embed_query(\"hope about the future\")\n",
    "query = 'SELECT \"Track\".\"Name\" FROM \"Track\" WHERE \"Track\".\"embeddings\" IS NOT NULL ORDER BY \"embeddings\" <-> ' +  f\"'{embeded_title}' LIMIT 5\"\n",
    "db.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the SQL Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to generate a query using the SQL chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.sql_database.prompt import PROMPT, SQL_PROMPTS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import create_sql_query_chain\n",
    "\n",
    "prompt = SQL_PROMPTS['postgresql']\n",
    "\n",
    "#TODO: Load prompt from LangChain HUB\n",
    "prompt.template = \"\"\"\n",
    "You are a PostgreSQL expert. Given an input question, first create a syntactically correct PostgreSQL query to run, then look at the results of the query and return the answer to the input question.\n",
    "Unless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per PostgreSQL. You can order the results to return the most informative data in the database.\n",
    "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
    "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "Pay attention to use CURRENT_DATE function to get the current date, if the question involves \"today\".\n",
    "\n",
    "IMPORTANT NOTE: you can use specialized pgvector syntax (`<->`) to run\n",
    "semantic search using an embeddings column in the table.\n",
    "The embeddings value for a given row typically represents the semantic meaning of that row.\n",
    "The vector represents an embedding representation of the question, given below. \n",
    "\n",
    "Do NOT fill in the vector values directly, but rather specify a\n",
    "`[search_word]` placeholder, which should contain the word that should be embedded for filtering.\n",
    "The column containing the embedding is called 'embeddings'.\n",
    "FOR EXAMPLE, if the user asks for songs about 'the feeling of loneliness' the query could be:\n",
    "'SELECT \"Track\".\"Name\" FROM \"Track\" ORDER BY \"embeddings\" <-> '[loneliness]' LIMIT 5'\n",
    "\n",
    "If you need to combine embeddings from different tables, you can use the WITH statement:\n",
    "WITH table1 AS (\n",
    "    SELECT \"ColumnName\"\n",
    "    FROM \"TableName\"\n",
    "    ORDER BY \"embeddings\" <-> '[keyword_1]'\n",
    "    LIMIT 5\n",
    ")\n",
    "SELECT \"table2\".\"Column_Name\", Table1.\"TableName\".\"ColumnName\"\n",
    "FROM \"table2\n",
    "JOIN table1 ON \"table2\".\"Column_Name\" = table1.\"ColumnName\"\n",
    "ORDER BY \"table2\".\"embeddings\" <-> '[keyword_2]'\n",
    "LIMIT 3;\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: Question here\n",
    "SQLQuery: SQL Query to run\n",
    "SQLResult: Result of the SQLQuery\n",
    "Answer: Final answer here\n",
    "\n",
    "Only use the following tables:\n",
    "{table_info}\n",
    "\n",
    "Question: {input}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(CONNECTION_STRING) # We reconnect to dbso the new columns are loaded as well.\n",
    "llm = ChatOpenAI(model_name='gpt-4', temperature=0)\n",
    "chain = create_sql_query_chain(llm, db, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Filtering a column based on semantic meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to retrieve songs that express sadness, but filtering based on genre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT \"Track\".\"Name\" \n",
      "FROM \"Track\" \n",
      "JOIN \"Genre\" ON \"Track\".\"GenreId\" = \"Genre\".\"GenreId\" \n",
      "WHERE \"Genre\".\"Name\" = 'Rock' \n",
      "ORDER BY \"Track\".\"embeddings\" <-> '[dispair]' \n",
      "LIMIT 5\n"
     ]
    }
   ],
   "source": [
    "question = \"Which are the 5 rock songs with titles about deep feeling of dispair?\"\n",
    "query = chain.invoke({\"question\": question})\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have a placeholder provided by the LLM for us to insert the actual embedding for `dispair`. \n",
    "\n",
    "Let's use this function to replace the embedding placeholder with the actual embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def replace_brackets(match):\n",
    "    words_inside_brackets = match.group(1).split(', ')\n",
    "    embedded_words = [str(embeddings_model.embed_query(word)) for word in words_inside_brackets]\n",
    "    return \"', '\".join(embedded_words)\n",
    "\n",
    "final_query = re.sub(r'\\[([\\w\\s,]+)\\]', replace_brackets, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`replace_brackets` takes a stringand replaces all occurrences of words or phrases inside square brackets with their corresponding embeddings.\n",
    "\n",
    "Embeddings are returned by `embeddings_model.embed_query()`. \n",
    "\n",
    "The embeddings are then concatenated into a single string, separated by commas.\n",
    "\n",
    "And we can run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('Sea Of Sorrow',), ('Surrender',), ('Indifference',), ('Hard Luck Woman',), ('Desire',)]\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(final_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some insights\n",
    "\n",
    "What is substantially different in implementing this method is that we have combined:\n",
    "- Semantic search (songs that have sad titles)\n",
    "- Traditional tabular querying (running JOIN statements to filter track based on genre)\n",
    "\n",
    "This is something we _could_ potentially achieve using metadata filtering, but it's more complex to do so (we would need to use a vector database containing the embeddings, and use metadata filtering based on genre).\n",
    "\n",
    "However, for other use cases metadata filtering **wouldn't be enough**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Combining filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"I want to know the 3 albums which have the most amount of songs in the top 150 saddest songs\"\n",
    "query = chain.invoke({\"question\": question})\n",
    "# print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('International Superhits', 5), ('Ten', 4), ('Album Of The Year', 3)]\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_query = re.sub(r'\\[([\\w\\s,]+)\\]', replace_brackets, query)\n",
    "db.run(final_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have result for 3 albums with most amount of songs in top 150 saddest ones. This **wouldn't** be possible using only standard metadata filtering. Without this _hybdrid query_, we would need some postprocessing to get the result.\n",
    "\n",
    "Another similar exmaple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT \"Album\".\"Title\", \"Album\".\"AlbumId\"\n",
      "FROM \"Album\"\n",
      "JOIN \"Track\" ON \"Album\".\"AlbumId\" = \"Track\".\"AlbumId\"\n",
      "WHERE \"Track\".\"TrackId\" IN (\n",
      "    SELECT \"TrackId\" \n",
      "    FROM \"Track\" \n",
      "    ORDER BY \"embeddings\" <-> '[sad]' \n",
      "    LIMIT 20\n",
      ")\n",
      "ORDER BY \"Album\".\"title_len\" ASC\n",
      "LIMIT 6\n"
     ]
    }
   ],
   "source": [
    "question = \"I need the 6 albums with shortest title, as long as they contain songs which are in the 20 saddest song list.\"\n",
    "query = chain.invoke({\"question\": question})\n",
    "# print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('Ten', 181), ('Core', 206), ('Big Ones', 5), ('One By One', 81), ('Black Album', 148), ('Miles Ahead', 157)]\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_query = re.sub(r'\\[([\\w\\s,]+)\\]', replace_brackets, query)\n",
    "db.run(final_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Combining two separate semantic searches\n",
    "\n",
    "One interesting aspect of this approach which is **substantially different from using standar RAG** is that we can even **combine** two semantic search filters:\n",
    "- _Get 5 saddest songs..._\n",
    "- _**...obtained from albums with \"lovely\" titles**_\n",
    "\n",
    "This could generalize to **any kind of combined RAG** (paragraphs discussing _X_ topic belonging from books about _Y_, replies to a tweet about _ABC_ topic that express _XYZ_ feeling)\n",
    "\n",
    "We will combine semantic search on songs and album titles, so we need to do the same for `Album` table:\n",
    "1. Generate the embeddings\n",
    "2. Add them to the table as a new column (which we need to add in the table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.run('ALTER TABLE \"Album\" ADD COLUMN \"embeddings\" vector;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "albums = db.run('SELECT \"Title\" FROM \"Album\"')\n",
    "album_titles = [title[0] for title in eval(albums)]\n",
    "album_title_embeddings = embeddings_model.embed_documents(album_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 347/347 [00:03<00:00, 114.59it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(album_title_embeddings))):\n",
    "    album_title = album_titles[i].replace(\"'\",\"''\")\n",
    "    album_embedding = album_title_embeddings[i]\n",
    "    sql_command = f'UPDATE \"Album\" SET \"embeddings\" = ARRAY{album_embedding} WHERE \"Title\" =' +  f\"'{album_title}'\"\n",
    "    db.run(sql_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('Realize',), ('Morning Dance',), ('Into The Light',), ('New Adventures In Hi-Fi',), ('Miles Ahead',)]\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_title = embeddings_model.embed_query(\"hope about the future\")\n",
    "query = 'SELECT \"Album\".\"Title\" FROM \"Album\" WHERE \"Album\".\"embeddings\" IS NOT NULL ORDER BY \"embeddings\" <-> ' +  f\"'{embeded_title}' LIMIT 5\"\n",
    "db.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can combine both filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(CONNECTION_STRING) # We reconnect to dbso the new columns are loaded as well.\n",
    "llm = ChatOpenAI(model_name='gpt-4', temperature=0)\n",
    "chain = create_sql_query_chain(llm, db, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"I want to know songs about love obtained from 5 saddest albums\"\n",
    "query = chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH SadAlbums AS (\n",
      "    SELECT \"AlbumId\"\n",
      "    FROM \"Album\"\n",
      "    ORDER BY \"embeddings\" <-> '[sadness]'\n",
      "    LIMIT 5\n",
      ")\n",
      "SELECT \"Track\".\"Name\"\n",
      "FROM \"Track\"\n",
      "JOIN SadAlbums ON \"Track\".\"AlbumId\" = SadAlbums.\"AlbumId\"\n",
      "ORDER BY \"Track\".\"embeddings\" <-> '[love]'\n",
      "LIMIT 5;\n"
     ]
    }
   ],
   "source": [
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('For Your Life',), ('Frantic',), ('Believer',), ('My World',), ('Dee',)]\""
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_query = re.sub(r'\\[([\\w\\s,]+)\\]', replace_brackets, query)\n",
    "db.run(final_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which are the 5 saddest albums?\"\n",
    "query = chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('St. Anger', 'Metallica'), ('Presence', 'Led Zeppelin'), ('Tribute', 'Ozzy Osbourne'), ('Quiet Songs', 'Aisha Duo'), ('Allegri: Miserere', 'Richard Marlow & The Choir of Trinity College, Cambridge')]\""
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(re.sub(r'\\[([\\w\\s,]+)\\]', replace_brackets, query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
