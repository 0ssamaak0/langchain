{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67f41c2c-869d-44c3-b243-a7ba105d504f",
   "metadata": {},
   "source": [
    "## Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27507adc-aeb4-4ed0-a4c3-593e03b01cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain unstructured[all-docs] pypdf langchainhub anthropic openai chromadb gpt4all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9b3675-2181-42a0-a491-4f1df69fb763",
   "metadata": {},
   "source": [
    "## Summarization\n",
    "\n",
    "### Document Loading \n",
    "\n",
    "* File: [Clinical trials of interest for 2023](https://www.nature.com/articles/s41591-022-02132-3)\n",
    "* Reference on loaders: [LangChain Docs](https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "849a98d2-f39a-4715-965b-40168190effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "path = \"/Users/rlm/Desktop/GENE-workshop/s41591-022-02132-3.pdf\"\n",
    "loader = PyPDFLoader(path)\n",
    "pdf_pages = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcbc23e-ad10-4723-be6e-6a184f733439",
   "metadata": {},
   "source": [
    "You can explore a broad set of loaders [here](https://python.langchain.com/docs/integrations/document_loaders) and [here](https://integrations.langchain.com/).\n",
    "\n",
    "For example, we can load from urls or [CSVs](https://python.langchain.com/docs/integrations/document_loaders/csv) (e.g., from [Clinical Trials](https://clinicaltrials.gov/study/NCT04296890)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "729327fc-6710-4c2f-8ae5-05c0c1b6ce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "blog = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d88873e-0449-4248-aa66-a29b0d59cbcb",
   "metadata": {},
   "source": [
    "### Prompt Definition \n",
    "\n",
    "* See list of OpenAI models [here](https://platform.openai.com/docs/models/gpt-3-5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0784c5-ad6e-4142-b4ab-0cea0801cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['OPENAI_API_KEY'] = 'xxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8e41ffd-08ff-49a4-a971-6ec54d61ea63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The article discusses 11 clinical trials that are expected to shape medicine in 2023. These trials cover a range of medical conditions, including Parkinson's disease, Alzheimer's disease, ovarian cancer, muscular dystrophy, cervical cancer, weight loss, sleeping sickness, metastatic breast cancer, and COVID-19 vaccination in individuals with HIV. Leading researchers provide insights into the significance and potential outcomes of these trials. The article highlights the challenges faced by the biopharmaceutical industry in 2022, including clinical trial failures and disruptions caused by COVID-19. Despite these challenges, the article emphasizes the potential for new advancements and breakthroughs in medicine in the coming year.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt \n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "template = \"\"\"Summarize the following context:\n",
    "{context}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# LLM\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm_openai = ChatOpenAI(model=\"gpt-3.5-turbo-16k\",temperature=0)\n",
    "\n",
    "# Chain\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "chain = prompt | llm_openai | StrOutputParser()\n",
    "\n",
    "# Docs\n",
    "all_pages = ' '.join([p.page_content for p in pdf_pages])\n",
    "\n",
    "# Invoke\n",
    "chain.invoke({\"context\" : all_pages})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639698ba-baad-497e-87d6-747f72e1596d",
   "metadata": {},
   "source": [
    "### LangSmith  \n",
    "\n",
    "* Use LangSmith to view the trace [here](https://smith.langchain.com/public/8fa348b6-3aa5-494f-bb3e-4e61bdc97744/r).\n",
    "* Reference on LangSmith: [here](https://docs.smith.langchain.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c14cf0-b15c-40da-af9a-da3fe6c3a129",
   "metadata": {},
   "source": [
    "### Vary the LLM and Prompt\n",
    "\n",
    "Claude2 has a [100k token context window](https://www.anthropic.com/index/claude-2).\n",
    "\n",
    "We can also use LangChain hub to explore different summarization prompts.\n",
    "  \n",
    "* [LangChain Docs](https://python.langchain.com/docs/integrations/chat/anthropic)\n",
    "* [LangChain Hub](https://blog.langchain.dev/langchain-prompt-hub/)\n",
    "* [Review of interesting prompts](https://blog.langchain.dev/the-prompt-landscape/)\n",
    "* [Example summarization prompt](https://smith.langchain.com/hub/hwchase17/anthropic-paper-qa?ref=blog.langchain.dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7a8bbfa-9e85-41f5-a2f9-9ac2b8435ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.chat_models import ChatAnthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fc90c2-70b7-4bda-963a-505934208913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['ANTHROPIC_API_KEY'] = 'xxx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e821f8-2a9b-48e6-9fa7-3ca1329d6d56",
   "metadata": {},
   "source": [
    "The summarization prompt is a fun, silly example to highlight the flexibility of Claude2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d29f57da-2369-4ab0-9ca2-b0d52ba7af05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' <kindergarten_abstract>\\nThe doctors did a bunch of studies to see what medicines and tests work best. They looked at medicines for Parkinson\\'s, Alzheimer\\'s, and other diseases. They also looked at tests for cancer and COVID vaccines. The results will help doctors treat patients better next year.\\n</kindergarten_abstract>\\n\\n<moosewood_methods>\\nIngredients:\\n- 11 leading medical experts\\n- A dash of speculation\\n- A pinch of prognostication\\n\\nInstructions:\\n1. Gather the experts in a room with coffee and pastries. Make sure they are well-caffeinated. \\n2. Ask each expert to name one clinical trial they are most excited about in 2023. Let them ramble on for a bit about the details. Take notes.\\n3. Stir the trials together and look for common themes. Do the trials focus on new drug treatments, improved screening methods, or preventative measures? Categorize accordingly.  \\n4. Sprinkle in some educated guesses about when results will be announced and potential impacts on medical practice.\\n5. Bake at 350 degrees for 1 news article. Let cool before serving.\\n</moosewood_methods>\\n\\n<homer_results>\\nOh Muses, sing of trials to come, \\nThat shape the fate of mortal men,\\nNew cures for ills that plague us now, \\nAnd tests to find disease again.\\n\\nOn treatments for the shaking palsied,\\nAnd medicines to still the mind, \\nThe wise doctors have pondered long,\\nHopeful results they soon shall find.\\n\\nOf cancer screens and vaccines too,\\nTo keep dread viruses at bay,\\nThe trials promise better paths,  \\nTo health and wellness show the way.\\n\\nThough challenges remain ahead,\\nScience marches steadily on,\\nGuided by patient volunteers,\\nWho progress help us carry on.\\n</homer_results>\\n\\n<grouchy_critique>\\nHmph, another puff piece about \"exciting\" clinical trials. The authors interviewed a bunch of optimistic \"experts\" who picked their favorite trials without any critical assessment. Of course they\\'re excited - they probably run the trials or have a stake in the treatments! But most early stage trials fail, and positive results often don\\'t replicate. Wake me up when phase 3 results are published in reputable journals, not press releases. This is just hype and speculation masquerading as news. Do some actual investigative reporting on research quality, instead of asking researchers to promote their own work! Bah!\\n</grouchy_critique>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt from the Hub\n",
    "prompt = hub.pull(\"hwchase17/anthropic-paper-qa\")\n",
    "\n",
    "# LLM\n",
    "llm_anthropic = ChatAnthropic(temperature=0, model='claude-2', max_tokens=10000)\n",
    "\n",
    "# Chain\n",
    "chain = prompt | llm_anthropic | StrOutputParser()\n",
    "\n",
    "# Invoke the chain\n",
    "chain.invoke({\"text\" : all_pages})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a42165-57a4-43c6-bed3-bf2555c39f80",
   "metadata": {},
   "source": [
    "## RAG \n",
    "\n",
    "We may want to perform question-answering based on document context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4eeeea4-d934-4a4f-9188-21f418185311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split documents\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(pdf_pages)\n",
    "\n",
    "# Embed and add to vectorDB\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    collection_name=\"rag\",\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "rag_prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# RAG chain\n",
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
    "chain = (\n",
    "    RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "    | rag_prompt\n",
    "    | llm_openai\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "976710f7-ebfc-41c3-8525-323315b2ab35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the given context, one example of a clinical trial focused on cancer is the trial for mirvetuximab soravtan-sine from ImmunoGen for platinum-resistant ovarian cancer.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What are some exmaple clincal trials that are focused on cancer?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5034e7c8-7dbb-4467-a3f7-14ffa2cfeab5",
   "metadata": {},
   "source": [
    "Look at LangSmith trace [here](https://smith.langchain.com/public/c87b797b-78ef-42de-a5f3-3986af379943/r)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e3b622-086e-4d16-891c-f05a41c27cfc",
   "metadata": {},
   "source": [
    "## Private RAG \n",
    "\n",
    "We may want to perform question-answering based on document context without passing anything to external APIs.\n",
    "\n",
    "We can use [Ollama.ai](https://ollama.ai/).\n",
    "\n",
    "Download the app, and then pull your LLM of choice:\n",
    "\n",
    "e.g., `ollama pull zephyr` for [Zephyr](https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha), a fine-tuned LLM on Mistral.\n",
    "\n",
    "Also, we will use local embeddings from GPT4All (CPU-optimized BERT embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1ed0d54-ad4a-4a55-9858-0777ee5274f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.embeddings import GPT4AllEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8381170-0e30-40bc-a92c-303e7bdea0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  /Users/rlm/.cache/gpt4all/ggml-all-MiniLM-L6-v2-f16.bin\n"
     ]
    }
   ],
   "source": [
    "# Add to vectorDB\n",
    "vectorstore_private = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    collection_name=\"rag-private\",\n",
    "    embedding=GPT4AllEmbeddings(),\n",
    ")\n",
    "retriever_private = vectorstore_private.as_retriever()\n",
    "\n",
    "# LLM\n",
    "ollama_llm = \"zephyr\"\n",
    "llm_private = ChatOllama(model=ollama_llm)\n",
    "\n",
    "# RAG chain\n",
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
    "chain_private = (\n",
    "    RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "    | rag_prompt\n",
    "    | llm_private\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afaa3d1e-a94f-41bc-bd60-b8c36adae219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Two examples of clinical trials that are focused on cancer mentioned in the given context are:\\n1. Mirvetuximab soravtan-sin, a antibody-drug conjugate (ADC) for ovarian cancer. This trial resulted in accelerated approval by the US Food and Drug Administration based on results from a single-arm study enrolling 106 patients with platinum-resistant ovarian cancer whose tumors had high expression of a protein called folate receptor alpha (FRA). The author, Robert L. Coleman, expects this to be the most imminent and important upcoming trial result in his field in 2023.\\n2. ADCs for previously treated cervical cancer, which are currently in development. Successful approval of these trials will provide a solid framework for clinical trials evaluating novel combinations in several disease settings.\\nNote: The first example provided is specifically for ovarian cancer, while the second example is more general and encompasses other types of cancer as well.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_private.invoke(\"What are some exmaple clincal trials that are focused on cancer?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48803980-2ffc-4ba8-a5e5-72b6e44295eb",
   "metadata": {},
   "source": [
    "## Semi-Structured RAG \n",
    "\n",
    "Cookbook here: \n",
    "\n",
    "https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_Structured_RAG.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76964c67-98c9-4f2a-a195-d27f2f382192",
   "metadata": {},
   "source": [
    "## Multi-Modal RAG\n",
    "\n",
    "Cookbook here:\n",
    "\n",
    "https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_structured_and_multi_modal_RAG.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77ba550-a80c-4104-88ec-08105af5c5fc",
   "metadata": {},
   "source": [
    "## Templates\n",
    "\n",
    "Laboratory plates:\n",
    "\n",
    "https://github.com/langchain-ai/langchain/tree/master/templates/plate-chain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
