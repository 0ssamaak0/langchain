{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c284df8",
   "metadata": {},
   "source": [
    "# XML Agent\n",
    "\n",
    "Some language models (like Anthropic's Claude) are particularly good at reasoning/writing XML. This goes over how to use an agent that uses XML when prompting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1f30fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_xml_agent\n",
    "from langchain_community.chat_models import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe972808",
   "metadata": {},
   "source": [
    "## Initialize the tools\n",
    "\n",
    "We will initialize the tools we want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e30e99e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [TavilySearchResults(max_results=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b300d66",
   "metadata": {},
   "source": [
    "## Create Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a63869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/xml-agent-convo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e4393dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['agent_scratchpad', 'chat_history', 'input', 'tools'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input', 'tools'], template=\"You are a helpful assistant. Help the user answer any questions.\\n\\nYou have access to the following tools:\\n\\n{tools}\\n\\nIn order to use a tool, you can use <tool></tool> and <tool_input></tool_input> tags. You will then get back a response in the form <observation></observation>\\nFor example, if you have a tool called 'search' that could run a google search, in order to search for the weather in SF you would respond:\\n\\n<tool>search</tool><tool_input>weather in SF</tool_input>\\n<observation>64 degrees</observation>\\n\\nWhen you are done, respond with a final answer between <final_answer></final_answer>. For example:\\n\\n<final_answer>The weather in SF is 64 degrees</final_answer>\\n\\nBegin!\\n\\nPrevious Conversation:\\n{chat_history}\\n\\nQuestion: {input}\\n{agent_scratchpad}\"))]\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5490f4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatAnthropic(model=\"claude-2\")\n",
    "\n",
    "# Construct the XML agent\n",
    "agent = create_xml_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c26d04",
   "metadata": {},
   "source": [
    "## Run the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e39b42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00d768aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m <tool>tavily_search_results_json</tool><tool_input>what is LangChain\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection error caused failure to post https://dev.api.langchain.plus/runs  in LangSmith API. Please confirm your LANGCHAIN_ENDPOINT. SSLError(MaxRetryError(\"HTTPSConnectionPool(host='dev.api.langchain.plus', port=443): Max retries exceeded with url: /runs (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))\"))\n",
      "Connection error caused failure to patch https://dev.api.langchain.plus/runs/bf02940c-83a6-45dc-90a4-afe87ba95fc6  in LangSmith API. Please confirm your LANGCHAIN_ENDPOINT. SSLError(MaxRetryError(\"HTTPSConnectionPool(host='dev.api.langchain.plus', port=443): Max retries exceeded with url: /runs/bf02940c-83a6-45dc-90a4-afe87ba95fc6 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[{'url': 'https://www.commandbar.com/blog/langchain-projects', 'content': 'What Is LangChain?  What Is The Role Of LangChain?  Guide to LangChain resource.  At its core, LangChain boasts modular components for efficient language model operations and off-the-shelf chainsLatest Update December 5, 2023 In the rapidly evolving world of technology, one tool is making waves and transforming the landscape: LangChain. This powerful tool is revolutionizing the way developers build applications using large language models.'}]\u001b[0m\u001b[32;1m\u001b[1;3m <final_answer>\n",
      "LangChain is a tool that enables developers to build applications using large language models in a modular and efficient way. It features reusable components for common language model operations, making it easier to create \"chains\" of models to power complex apps. Some key things to know about LangChain:\n",
      "\n",
      "- It facilitates the use of large language models like GPT-3 for developers by handling tedious tasks like prompt engineering and chaining models together.\n",
      "\n",
      "- It has modular components so developers can mix and match different models and tools instead of building everything from scratch.\n",
      "\n",
      "- It aims to make building with language models more accessible and production-ready.\n",
      "\n",
      "- LangChain helps manage costs, efficiency, and scaling when using expensive language model APIs.\n",
      "\n",
      "So in summary, LangChain is an open-source library focused on streamlining the process of leveraging large language models to build useful applications. It abstracts away a lot of complexity for developers.\n",
      "</final_answer>\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is LangChain?',\n",
       " 'output': '\\nLangChain is a tool that enables developers to build applications using large language models in a modular and efficient way. It features reusable components for common language model operations, making it easier to create \"chains\" of models to power complex apps. Some key things to know about LangChain:\\n\\n- It facilitates the use of large language models like GPT-3 for developers by handling tedious tasks like prompt engineering and chaining models together.\\n\\n- It has modular components so developers can mix and match different models and tools instead of building everything from scratch.\\n\\n- It aims to make building with language models more accessible and production-ready.\\n\\n- LangChain helps manage costs, efficiency, and scaling when using expensive language model APIs.\\n\\nSo in summary, LangChain is an open-source library focused on streamlining the process of leveraging large language models to build useful applications. It abstracts away a lot of complexity for developers.\\n'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"what is LangChain?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f83099",
   "metadata": {},
   "source": [
    "## Use LangChain Expression Language\n",
    "\n",
    "We will first show how to create this agent using LangChain Expression Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78937679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents.format_scratchpad import format_xml\n",
    "from langchain.agents.output_parsers import XMLAgentOutputParser\n",
    "from langchain.tools.render import render_text_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54fc5a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"hwchase17/xml-agent-convo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1802fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt.partial(\n",
    "    tools=render_text_description(tools),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9d2ead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_stop = llm.bind(stop=[\"</tool_input>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebadf04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_xml(x[\"intermediate_steps\"]),\n",
    "        # Give it a default\n",
    "        \"chat_history\": lambda x: x.get(\"chat_history\", \"\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_stop\n",
    "    | XMLAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e2bb03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ce9f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e14affef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m <tool>tavily_search_results_json</tool><tool_input>what is LangChain\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.commandbar.com/blog/langchain-projects', 'content': 'What Is LangChain?  What Is The Role Of LangChain?  Guide to LangChain resource.  At its core, LangChain boasts modular components for efficient language model operations and off-the-shelf chainsLatest Update December 5, 2023 In the rapidly evolving world of technology, one tool is making waves and transforming the landscape: LangChain. This powerful tool is revolutionizing the way developers build applications using large language models.'}]\u001b[0m\u001b[32;1m\u001b[1;3m <final_answer>\n",
      "LangChain is a tool for building modular pipelines that connect language models and other components. It allows developers to efficiently chain together different models and data sources to create custom AI applications.\n",
      "\n",
      "Some key things to know about LangChain:\n",
      "\n",
      "- It provides a framework for connecting modular components like language models (e.g. GPT-3), search engines, databases, etc.\n",
      "\n",
      "- It makes it easier to build pipelines and workflows that leverage large language models. \n",
      "\n",
      "- It aims to simplify and streamline the process of creating AI apps with language models.\n",
      "\n",
      "- By handling coordination and data flow behind the scenes, LangChain frees up developers to focus on the functionality and UX of their applications.\n",
      "\n",
      "So in summary, LangChain is an open-source library for efficiently leveraging large language models to build custom AI tools and products. It streamlines the process by providing infrastructure and abstractions for linking together different components.\n",
      "</final_answer>\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is LangChain?',\n",
       " 'output': '\\nLangChain is a tool for building modular pipelines that connect language models and other components. It allows developers to efficiently chain together different models and data sources to create custom AI applications.\\n\\nSome key things to know about LangChain:\\n\\n- It provides a framework for connecting modular components like language models (e.g. GPT-3), search engines, databases, etc.\\n\\n- It makes it easier to build pipelines and workflows that leverage large language models. \\n\\n- It aims to simplify and streamline the process of creating AI apps with language models.\\n\\n- By handling coordination and data flow behind the scenes, LangChain frees up developers to focus on the functionality and UX of their applications.\\n\\nSo in summary, LangChain is an open-source library for efficiently leveraging large language models to build custom AI tools and products. It streamlines the process by providing infrastructure and abstractions for linking together different components.\\n'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"what is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca87246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
