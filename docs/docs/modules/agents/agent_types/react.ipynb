{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2014ffc4",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_position: 6\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82e62ec",
   "metadata": {},
   "source": [
    "# ReAct\n",
    "\n",
    "This walkthrough showcases using an agent to implement the [ReAct](https://react-lm.github.io/) logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "102b0e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d779225",
   "metadata": {},
   "source": [
    "## Initialize tools\n",
    "\n",
    "Let's load some tools to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256408d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [TavilySearchResults(max_results=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e94831",
   "metadata": {},
   "source": [
    "## Create Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a33a16a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/react\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22ff2077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the LLM to use\n",
    "llm = OpenAI()\n",
    "\n",
    "# Construct the ReAct agent\n",
    "agent = create_react_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e808f8",
   "metadata": {},
   "source": [
    "## Run Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6e46c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "443f66d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m LangChain is probably a word that refers to something specific. It's best to use a search engine to find out more information.\n",
      "Action: tavily_search_results_json\n",
      "Action Input: LangChain\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.ibm.com/topics/langchain', 'content': 'LangChain is essentially a library of abstractions for Python and Javascript, representing common steps and concepts  LangChain is an open source orchestration framework for the development of applications using large language models  other LangChain features, like the eponymous chains.  LangChain provides integrations for over 25 different embedding methods, as well as for over 50 different vector storesLangChain is a tool for building applications using large language models (LLMs) like chatbots and virtual agents. It simplifies the process of programming and integration with external data sources and software workflows. It supports Python and Javascript languages and supports various LLM providers, including OpenAI, Google, and IBM.'}]\u001b[0m\u001b[32;1m\u001b[1;3mI should take a look at the information provided and see if it answers my question.\n",
      "Action: tavily_search_results_json\n",
      "Action Input: LangChain\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.ibm.com/topics/langchain', 'content': 'LangChain is essentially a library of abstractions for Python and Javascript, representing common steps and concepts  LangChain is an open source orchestration framework for the development of applications using large language models  other LangChain features, like the eponymous chains.  LangChain provides integrations for over 25 different embedding methods, as well as for over 50 different vector storesLangChain is a tool for building applications using large language models (LLMs) like chatbots and virtual agents. It simplifies the process of programming and integration with external data sources and software workflows. It supports Python and Javascript languages and supports various LLM providers, including OpenAI, Google, and IBM.'}]\u001b[0m\u001b[32;1m\u001b[1;3mIt seems like LangChain is a tool used for building applications using large language models and is available for Python and Javascript languages.\n",
      "Final Answer: LangChain is a tool for building applications using large language models and is available for Python and Javascript languages.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is LangChain?',\n",
       " 'output': 'LangChain is a tool for building applications using large language models and is available for Python and Javascript languages.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"what is LangChain?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40a042c",
   "metadata": {},
   "source": [
    "## Using with chat history\n",
    "\n",
    "When using with chat history, we will need a prompt that takes that into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a16d7907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/react-chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af2cfb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the ReAct agent\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35d7b643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "Final Answer: Your name is Bob.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"what's my name? Only use a tool if needed, otherwise respond with Final Answer\",\n",
       " 'chat_history': 'Human: Hi! My name is Bob\\nAI: Hello Bob! Nice to meet you',\n",
       " 'output': 'Your name is Bob.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"what's my name? Only use a tool if needed, otherwise respond with Final Answer\",\n",
    "        # Notice that chat_history is a string, since this prompt is aimed at LLMs, not chat models\n",
    "        \"chat_history\": \"Human: Hi! My name is Bob\\nAI: Hello Bob! Nice to meet you\",\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
