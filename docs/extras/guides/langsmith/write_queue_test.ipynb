{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29c5612f-2d85-4fd4-a13a-40145642847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from uuid import uuid4\n",
    "from typing import Any, Dict, List, Mapping, Optional, cast\n",
    "\n",
    "unique_id = uuid4().hex[0:8]\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Tracing With Write Queue - {unique_id}\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://dev.api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"\"  # Update to your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b4dfa5-5c14-49c7-977b-5b13ffc13d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ea2c036-4d68-4472-9c24-d3fdf6cae5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeLLM(LLM):\n",
    "    \"\"\"Fake LLM wrapper for testing purposes.\"\"\"\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Return type of llm.\"\"\"\n",
    "        return \"fake\"\n",
    "    \n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        return \"This is a fake response\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ecf96f5-54fa-4d38-8510-be2af589dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\"This is a test {input}\")\n",
    "model = FakeLLM()\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7771bdb8-a8f7-46e0-bd74-1ab94040114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def task():\n",
    "    return await chain.ainvoke({\"input\": \"test\"})\n",
    "\n",
    "async def chunked_gather(func, n, chunk_size):\n",
    "    \"\"\"Run func n times, chunk_size concurrently.\"\"\"\n",
    "    for _ in range(0, n, chunk_size):\n",
    "        tasks = [func() for _ in range(chunk_size)]\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "await chunked_gather(task, 10000, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfad08e-cfa1-434a-9235-959e9e760162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
