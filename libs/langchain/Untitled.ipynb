{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2629b03-534a-439f-9895-7e551817be7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c35e2fb-c3b9-4ff6-ba42-8919cc789545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "chat_model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5530b714-1e5e-45d5-bab7-96a90b99e71c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit error.\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit error.\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit error.\n",
      "Error in on_retry: asyncio.run() cannot be called from a running event loop\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tenacity/__init__.py:338: RuntimeWarning: coroutine 'AsyncCallbackManagerForLLMRun.on_retry' was never awaited\n",
      "  self.before_sleep(retry_state)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "Retrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit error.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NR responder\\n\\nLLMNR (Link-Local Multicast Name Resolution) is a protocol that allows devices to resolve the names of other devices on the local network. An LLMNR responder is a piece of software that responds to queries from other devices using the LLMNR protocol. LLMNR responders are typically installed as part of the operating system on Windows, macOS, and Linux systems. Common open-source LLMNR responders include LMNRD and Avahi.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"Sync LLM\")\n",
    "await llm.apredict(\"Async LLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff512507-c6be-4235-9327-a7fa12d7c3a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit error.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit error.\n",
      "Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit error.\n",
      "Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit error.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.predict(\"Sync Chat\")\n",
    "await chat_model.apredict(\"Async Chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a60786bc-3b6f-4432-9fa0-0b405e912ff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from itertools import islice\n",
    "\n",
    "client = Client()\n",
    "runs = list(islice(client.list_runs(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "801b8282-8a40-4c43-a511-6c078edd7c49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'start', 'time': '2023-07-21T20:51:36.214448'}, {'name': 'end', 'time': '2023-07-21T20:51:44.967533'}]\n",
      "[{'name': 'start', 'time': '2023-07-21T20:51:26.928913'}, {'name': 'retry', 'time': '2023-07-21T20:51:26.930591', 'kwargs': {'slept': 4.0, 'attempt': 1, 'outcome': 'failed', 'exception': 'Rate limit error', 'exception_cls': 'RateLimitError', 'outcome_timestamp': 584768.725407458}}, {'name': 'retry', 'time': '2023-07-21T20:51:30.938017', 'kwargs': {'slept': 8.0, 'attempt': 2, 'outcome': 'failed', 'exception': 'Rate limit error', 'exception_cls': 'RateLimitError', 'outcome_timestamp': 584772.73134625}}, {'name': 'end', 'time': '2023-07-21T20:51:36.203614'}]\n",
      "[{'name': 'start', 'time': '2023-07-21T20:50:40.005962'}, {'name': 'end', 'time': '2023-07-21T20:50:48.876328'}]\n",
      "[{'name': 'start', 'time': '2023-07-21T20:50:30.969464'}, {'name': 'retry', 'time': '2023-07-21T20:50:30.971400', 'kwargs': {'slept': 4.0, 'attempt': 1, 'outcome': 'failed', 'exception': 'Rate limit error', 'exception_cls': 'RateLimitError', 'outcome_timestamp': 584712.766095791}}, {'name': 'retry', 'time': '2023-07-21T20:50:34.990150', 'kwargs': {'slept': 8.0, 'attempt': 2, 'outcome': 'failed', 'exception': 'Rate limit error', 'exception_cls': 'RateLimitError', 'outcome_timestamp': 584716.784364416}}, {'name': 'end', 'time': '2023-07-21T20:50:39.997683'}]\n"
     ]
    }
   ],
   "source": [
    "for run in runs:\n",
    "    print(run.events)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
